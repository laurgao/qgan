{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tutorial - Building a QGAN to Generate a Two-Qubit State Using Pennylane and Tensorflow\n",
    "\n",
    "Generative adversarial networks (GANs) are fundamentally composed of two \"characters\" - a generator and a discriminator. By putting these two buddies \"to war\", we will result in an outcome when the data that the generator generates becomes equal to the real data, even though *the generator is never told what the real data is.* That's essentially the purpose of a GAN - to generate data that mimics some sort of real data, whether it's generating pictures of people that mimics real pictures or generating counterfeit bills that mimic real bills. This blog post will focus on the technical implementation details of a quantum GAN (QGAN) that can generate a 2-qubit state. If you're looking to build a theoretical understanding, I recommend [this video](https://www.loom.com/share/84b7e69fdc764e6fbc98836a82175c1f). \n",
    "\n",
    "In a classical GAN, the generator and discriminator are created as neural networks. In a quantum GAN, the generator and discriminator are created as *quantum neural networks* (QNNs), or, parametized quantum circuits (PQCs). (These two terms refer to the same thing.)\n",
    "\n",
    "\n",
    "![](https://d30uef581frdjs.cloudfront.net/6042905542b21b000856ec87/60429176c15e4300086b748d/ek6okLsMEANLgtU3JepKdk-image.png)\n",
    "\n",
    "Image source: [@EliesMiquel on Twitter](https://twitter.com/EliesMiquel/status/1362089454006128640)\n",
    "\n",
    "\n",
    "We start off with our imports:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import tensorflow as tf\n",
    "from pennylane import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "source": [
    "# Quantum Circuit Architecture\n",
    "\n",
    "I used 5 qubits:\n",
    "* Qubit 0 & 1: the 2 qubit state that we are trying to generate\n",
    "* Qubit 2 & 3: the generator's playground\n",
    "* Qubit 4: the generator's guess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_wires = 5\n",
    "\n",
    "dev = qml.device('cirq.simulator', wires=num_wires)"
   ]
  },
  {
   "source": [
    "The generator QNN/parametized circuit looks like this:\n",
    "\n",
    "![](https://d30uef581frdjs.cloudfront.net/6042905542b21b000856ec87/60429176c15e4300086b748d/izsro27NDCxZEnedRED8L7-2-qubit-generator.png)\n",
    "\n",
    "I chose to use 3 layers, quite arbitrarily, because I don't know how you're meant to choose. In the future, I can experiment with different ansatzes that have more layers. The architecture of each layer is modelled of of the proposed ansatz in [Dallaire-Demers and Killoran (2018)](https://journals.aps.org/pra/abstract/10.1103/PhysRevA.98.012324):\n",
    "\n",
    "![](https://d30uef581frdjs.cloudfront.net/6042905542b21b000856ec87/60429176c15e4300086b748d/6Wzs4jL9U7b2Vej7ZV6hx7-2-qubit-generator-layers.png)\n",
    "\n",
    "(Using the Pennylane printed circuit because ~~I'm too lazy to draw my own~~ it does the job, hence it meets speck. \\[^speck\\])"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator\n",
    "# Wires 0 and 1 are the 2 qubit state. \n",
    "def generator(w, **kwargs):\n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.CNOT(wires=[0,1])\n",
    "    generator_layer(w[:11])\n",
    "    generator_layer(w[11:22])\n",
    "    generator_layer(w[22:33]) # includes w[22], doesnt include w[33]\n",
    "    qml.RX(w[33], wires=0)\n",
    "    qml.RY(w[34], wires=0)\n",
    "    qml.RZ(w[35], wires=0)\n",
    "    qml.RX(w[36], wires=1)\n",
    "    qml.RY(w[37], wires=1)\n",
    "    qml.RZ(w[38], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RX(w[39], wires=0)\n",
    "    qml.RY(w[40], wires=0)\n",
    "    qml.RZ(w[41], wires=0)\n",
    "    qml.RX(w[42], wires=1)\n",
    "    qml.RY(w[43], wires=1)\n",
    "    qml.RZ(w[44], wires=1)\n",
    "\n",
    "def generator_layer(w):\n",
    "    qml.RX(w[0], wires=0)\n",
    "    qml.RX(w[1], wires=1)\n",
    "    qml.RX(w[2], wires=2)\n",
    "    qml.RX(w[3], wires=3)\n",
    "    qml.RZ(w[4], wires=0)\n",
    "    qml.RZ(w[5], wires=1)\n",
    "    qml.RZ(w[6], wires=2)\n",
    "    qml.RZ(w[7], wires=3)\n",
    "    qml.MultiRZ(w[8], wires=[0, 1])\n",
    "    qml.MultiRZ(w[9], wires=[2, 3])\n",
    "    qml.MultiRZ(w[10], wires=[1, 2])\n",
    "    # 11 weights"
   ]
  },
  {
   "source": [
    "Here's what the discriminator architecture looks like:\n",
    "![](https://d30uef581frdjs.cloudfront.net/6042905542b21b000856ec87/60429176c15e4300086b748d/jk8rMEkwJkY772T4aDwNgm-2-qubit-discriminator.png)\n",
    "\n",
    "As well as each discriminator layer:\n",
    "![](https://d30uef581frdjs.cloudfront.net/6042905542b21b000856ec87/60429176c15e4300086b748d/vtvEvUWX8fZZvR6RXjb48E-2-qubit-discriminator-layer.png)\n",
    "\n",
    "As well as the code to create that:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The discriminator acts on wires 0, 1, and 4\n",
    "\n",
    "def discriminator_layer(w, **kwargs):\n",
    "    qml.RX(w[0], wires=0)\n",
    "    qml.RX(w[1], wires=1)\n",
    "    qml.RX(w[2], wires=4)\n",
    "    qml.RZ(w[3], wires=0)\n",
    "    qml.RZ(w[4], wires=1)\n",
    "    qml.RZ(w[5], wires=4)\n",
    "    qml.MultiRZ(w[6], wires=[0, 1])\n",
    "    qml.MultiRZ(w[7], wires=[1, 4])\n",
    "\n",
    "def discriminator(w, **kwargs):\n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.CNOT(wires=[0,1])\n",
    "    discriminator_layer(w[:8])\n",
    "    discriminator_layer(w[8:16]) \n",
    "    discriminator_layer(w[16:32])\n",
    "    qml.RX(w[32], wires=4)\n",
    "    qml.RY(w[33], wires=4)\n",
    "    qml.RZ(w[34], wires=4)"
   ]
  },
  {
   "source": [
    "The real data circuit architecture:\n",
    "\n",
    "![](https://d30uef581frdjs.cloudfront.net/6042905542b21b000856ec87/60429176c15e4300086b748d/vqrDhHtcvLsGpKcWV761b1-2-qubit-real.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the real data creator\n",
    "def real_data(phi, **kwargs):\n",
    "    # phi is a list with length 12\n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.CNOT(wires=[0,1])\n",
    "    qml.RX(phi[0], wires=0)\n",
    "    qml.RY(phi[1], wires=0)\n",
    "    qml.RZ(phi[2], wires=0)\n",
    "    qml.RX(phi[3], wires=0)\n",
    "    qml.RY(phi[4], wires=0)\n",
    "    qml.RZ(phi[5], wires=0)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RX(phi[6], wires=1)\n",
    "    qml.RY(phi[7], wires=1)\n",
    "    qml.RZ(phi[8], wires=1)\n",
    "    qml.RX(phi[9], wires=1)\n",
    "    qml.RY(phi[10], wires=1)\n",
    "    qml.RZ(phi[11], wires=1)"
   ]
  },
  {
   "source": [
    "We will use two quantum nodes, just like what we did in the GAN to [generate](https://postulate.us/@laura/p/2021-04-04-A-QGAN-to-generate-a-o5mTUu5SgHrwyKpqQvTAho) a single qubit state, and just like what we do in all GANs: \n",
    "> 1. Realdata-discriminator circuit - this circuit will output an expectation value that is proportional to **the probability of the discriminator classifying real data as real**\n",
    "> \n",
    "> 2. Generator-discriminator circuit - this circuit will output an expectation value that is proportional to **the probability of the discriminator classifying fake data as real**\n",
    "\n",
    "We return the expectation value of the wire 4 for both QNodes. In [the Pennylane tutorial](https://pennylane.ai/qml/demos/tutorial_QGAN.html), the expectation value was taken in the z basis. I don't know why the z basis was chosen or why it was chosen, but to play it safe, I also used the z basis in my model.\n",
    "\n",
    "![](https://d30uef581frdjs.cloudfront.net/6042905542b21b000856ec87/60429176c15e4300086b748d/fUU7i8vFgwN3eBcR79isiy-2-qubit-real-discriminator.png)\n",
    "\n",
    "![](https://d30uef581frdjs.cloudfront.net/6042905542b21b000856ec87/60429176c15e4300086b748d/spGFbcBpmeU1TdLYw7ki3N-2-qubit-gen-discriminator.png)\n",
    "\n",
    "To build these QNodes:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface='tf')\n",
    "def real_discriminator(phi, discriminator_weights):\n",
    "    real_data(phi)\n",
    "    discriminator(discriminator_weights)\n",
    "    return qml.expval(qml.PauliZ(4))\n",
    "\n",
    "@qml.qnode(dev, interface='tf')\n",
    "def generator_discriminator(generator_weights, discriminator_weights):\n",
    "    generator(generator_weights)\n",
    "    discriminator(discriminator_weights)\n",
    "    return qml.expval(qml.PauliZ(4))"
   ]
  },
  {
   "source": [
    "The circuit architecture is done!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Cost Functions\n",
    "We will need two cost functions: one for training the generator, and one for training the discriminator. These are defined in the same way as the ones used to [generate](https://postulate.us/@laura/p/2021-04-04-A-QGAN-to-generate-a-o5mTUu5SgHrwyKpqQvTAho) a single-qubit state:\n",
    "\n",
    "> The discriminator is trying to maximize correct guesses and minimize incorrect ones. The accuracy of the discriminator is given by the probability of the discriminator classifying real data as real - the probability of the discriminator classifying fake data as real, and thus, the cost function will be QNode2 output - QNode1 ouptut.\n",
    "> \n",
    "> The generator is trying to maximize how much it can fool the generator, so its accuracy is given by the probability of the discriminator classifying fake data as real, and its cost function would just be the additive inverse of that, aka the QNode2 output."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_real_real(discriminator_weights):\n",
    "    # probability of guessing real data as real\n",
    "    discriminator_output = real_discriminator(phi, discriminator_weights)\n",
    "    probability_real_real = (discriminator_output + 1) / 2\n",
    "    return probability_real_real\n",
    "\n",
    "def probability_fake_real(generator_weights, discriminator_weights):\n",
    "    # probability of guessing real fake as real\n",
    "    discriminator_output = generator_discriminator(generator_weights, discriminator_weights)\n",
    "    probability_fake_real = (discriminator_output + 1) / 2\n",
    "    return probability_fake_real\n",
    "       \n",
    "def discriminator_cost(discriminator_weights):\n",
    "    accuracy = probability_real_real(discriminator_weights) - probability_fake_real(generator_weights, discriminator_weights)\n",
    "    cost = -accuracy    \n",
    "    return cost\n",
    "\n",
    "def generator_cost(generator_weights):\n",
    "    accuracy = probability_fake_real(generator_weights, discriminator_weights)\n",
    "    cost = -accuracy\n",
    "    return cost"
   ]
  },
  {
   "source": [
    "The cost functions are done!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Training, aka Optimization\n",
    "We define the weights and turn them into Tensorflow-objects, because [Tensorflow optimizers need their parameters to be Tensorflow-type objects](https://postulate.us/@laura/p/2021-04-04-Tensorflow-optimizers-need-their-parameters-7Z6qWMaKvMZVwomByAkCC1)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# variables\n",
    "phi = [np.pi] * 12\n",
    "for i in range(len(phi)):\n",
    "    phi[i] = phi[i] / np.random.randint(2, 11)\n",
    "num_epochs = 30\n",
    "eps = 1 \n",
    "\n",
    "initial_generator_weights = np.array([np.pi] + [0] * 44) + \\\n",
    "    np.random.normal(scale=eps, size=(45,))\n",
    "initial_discriminator_weights = np.random.normal(scale=eps, size=(35,))\n",
    "\n",
    "generator_weights = tf.Variable(initial_generator_weights)\n",
    "discriminator_weights = tf.Variable(initial_discriminator_weights)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "35\n",
      "\n",
      "Cost: 0.019803181290626526\n",
      "\n",
      "Probability classify real as real:  0.45531943440437317\n",
      "\n",
      "Probability classify fake as real:  0.8116009086370468\n"
     ]
    }
   ],
   "source": [
    "# Let's run some tests first to make sure the circuitry works.\n",
    "print(len(initial_discriminator_weights))\n",
    "print('\\nCost:', discriminator_cost(discriminator_weights).numpy())\n",
    "print('\\nProbability classify real as real: ', probability_real_real(generator_weights).numpy())\n",
    "print('\\nProbability classify fake as real: ', probability_fake_real(generator_weights, discriminator_weights).numpy())"
   ]
  },
  {
   "source": [
    "Declare our Tensorflow optimizer:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(0.4)"
   ]
  },
  {
   "source": [
    "To make it easy to train the generator and discriminator against each other, we will define functions:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_discriminator():\n",
    "    for epoch in range(num_epochs):\n",
    "        cost = lambda: discriminator_cost(discriminator_weights) # you need \"lambda\" because discriminator_weights is a Tensorflow object\n",
    "        opt.minimize(cost, discriminator_weights)\n",
    "        if epoch % 5 == 0:\n",
    "            cost_val = discriminator_cost(discriminator_weights).numpy()\n",
    "            print('Epoch  {}/{}, Cost: {}, Probability class real as real: {}'.format(epoch, num_epochs, cost_val, probability_real_real(discriminator_weights).numpy()))\n",
    "        if epoch == num_epochs - 1:\n",
    "            print('\\n')\n",
    "\n",
    "def train_generator():\n",
    "    for epoch in range(num_epochs):\n",
    "        cost = lambda: generator_cost(generator_weights)\n",
    "        opt.minimize(cost, generator_weights)\n",
    "        if epoch % 5 == 0:\n",
    "            cost_val = generator_cost(generator_weights).numpy()\n",
    "            print('Epoch  {}/{}, Cost: {}, Probability class fake as real: {}'.format(epoch, num_epochs, cost_val, probability_fake_real(generator_weights, discriminator_weights).numpy()))\n",
    "        if epoch == num_epochs - 1:\n",
    "            print('\\n')"
   ]
  },
  {
   "source": [
    "Now it's time for the fun part, what all this work was for! Start putting the discriminator and generator to war by training them against each other:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch  0/30, Cost: 0.016384251415729523, Probability class real as real: 0.8018914610147476\n",
      "Epoch  5/30, Cost: 0.0025900080800056458, Probability class real as real: 0.8397957384586334\n",
      "Epoch  10/30, Cost: -0.013791278004646301, Probability class real as real: 0.8585737869143486\n",
      "Epoch  15/30, Cost: -0.05114398151636124, Probability class real as real: 0.8515666350722313\n",
      "Epoch  20/30, Cost: -0.1774560660123825, Probability class real as real: 0.8271761536598206\n",
      "Epoch  25/30, Cost: -0.47456610575318336, Probability class real as real: 0.9079123623669147\n",
      "\n",
      "\n",
      "Epoch  0/30, Cost: -0.5134937018156052, Probability class fake as real: 0.5134937018156052\n",
      "Epoch  5/30, Cost: -0.9647348411381245, Probability class fake as real: 0.9647348411381245\n",
      "Epoch  10/30, Cost: -0.9905945546925068, Probability class fake as real: 0.9905945546925068\n",
      "Epoch  15/30, Cost: -0.9939185006078333, Probability class fake as real: 0.9939185006078333\n",
      "Epoch  20/30, Cost: -0.9952942144591361, Probability class fake as real: 0.9952942144591361\n",
      "Epoch  25/30, Cost: -0.9961031721904874, Probability class fake as real: 0.9961031721904874\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_discriminator()\n",
    "train_generator()"
   ]
  },
  {
   "source": [
    "And again:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch  0/30, Cost: 0.013085490791127086, Probability class real as real: 0.9817191222682595\n",
      "Epoch  5/30, Cost: -0.05683990567922592, Probability class real as real: 0.9347136579453945\n",
      "Epoch  10/30, Cost: -0.28723930567502975, Probability class real as real: 0.7926171645522118\n",
      "Epoch  15/30, Cost: -0.7114340290427208, Probability class real as real: 0.8490715846419334\n",
      "Epoch  20/30, Cost: -0.7902502901852131, Probability class real as real: 0.8959890566766262\n",
      "Epoch  25/30, Cost: -0.8010090216994286, Probability class real as real: 0.9103046432137489\n",
      "\n",
      "\n",
      "Epoch  0/30, Cost: -0.22221961617469788, Probability class fake as real: 0.22221961617469788\n",
      "Epoch  5/30, Cost: -0.9474421814084053, Probability class fake as real: 0.9474421814084053\n",
      "Epoch  10/30, Cost: -0.9798047197982669, Probability class fake as real: 0.9798047197982669\n",
      "Epoch  15/30, Cost: -0.9853136069141328, Probability class fake as real: 0.9853136069141328\n",
      "Epoch  20/30, Cost: -0.9882683400064707, Probability class fake as real: 0.9882683400064707\n",
      "Epoch  25/30, Cost: -0.990305517334491, Probability class fake as real: 0.990305517334491\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_discriminator()\n",
    "train_generator()"
   ]
  },
  {
   "source": [
    "You can keep pitting these circuits against each other for as many times as you want! As for me, I'll be satisfied with a 91% discriminator accuracy and 99% generator accuracy.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real Bloch vector: [ 4.49031681e-01  8.68634649e-01  1.49011612e-07 -7.46617287e-01\n  5.78252882e-01 -2.53656507e-01]\n\nGenerator Bloch vector: [ 0.32962847  0.81327445  0.24301034 -0.68318889  0.49043131 -0.35765988]\n\nDifference: [0.11940321 0.0553602  0.24301019 0.0634284  0.08782157 0.10400337]\n\nAccuracy: 0.9642948114019914\n"
     ]
    }
   ],
   "source": [
    "obs = [qml.PauliX(0), qml.PauliY(0), qml.PauliZ(0), qml.PauliX(1), qml.PauliY(1), qml.PauliZ(1)] # the observation matrix - you measure both qubits 0 and 1 in the PauliX, PauliY, and PauliZ bases\n",
    "\n",
    "bloch_vector_real = qml.map(real_data, obs, dev, interface=\"tf\") # creates a QNode collection\n",
    "bloch_vector_generator = qml.map(generator, obs, dev, interface=\"tf\")\n",
    "\n",
    "bloch_vector_realz = bloch_vector_real(phi) # here: you pass phi through the QNode collection\n",
    "bloch_vector_generatorz = bloch_vector_generator(generator_weights) # calling it with a bloch_vector_generatorz at the end because adding _2 at the end is boring.\n",
    "\n",
    "difference = np.absolute(bloch_vector_generatorz - bloch_vector_realz)\n",
    "accuracy = difference / (np.pi) # It is divided by pi and not 2pi because a rotation of pi is maximum far-away-ness.\n",
    "\n",
    "# Find the mean of the accuracy\n",
    "average_accuracy = 0\n",
    "for i in range(len(accuracy)):\n",
    "    average_accuracy += accuracy[i]\n",
    "average_accuracy = average_accuracy / len(accuracy)\n",
    "average_accuracy = 1 - average_accuracy\n",
    "\n",
    "print(\"Real Bloch vector: {}\".format(bloch_vector_realz))\n",
    "print('')\n",
    "print(\"Generator Bloch vector: {}\".format(bloch_vector_generatorz))\n",
    "print('')\n",
    "print(\"Difference: {}\".format(difference))\n",
    "print('')\n",
    "print(\"Accuracy: {}\".format(average_accuracy))"
   ]
  },
  {
   "source": [
    "How that average_accuracy variable should be read is not that it is 96% accurate but that the generated two-qubit-state is within a 4% standard deviation away from the real state."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "I wrote a [blog post](https://postulate.us/@laura/p/2021-04-09-How-to-find-the-bloch-xusTUZ5o4KvofChkviMUkM) to explain why the above code is successful at retreiving the Bloch vectors.\n",
    "\n",
    "With that, we have successfully generated the two-qubit state!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Footnote\n",
    "\\[^speck\\]: Speck is an idea that Seth Godin [talks about](https://fs.blog/knowledge-project/seth-godin/) which states that the definition of whether something is high quality is if it meets speck. If your work has met speck, yes, it can be made better, but there's no point of making it any better."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 0: ──H──────────╭C──────────RX(-1.66)───RZ(1.53)───╭X──RZ(-1.08)──╭X───RX(0.749)──RZ(-0.837)──────────────────────────────╭X──RZ(-1.54)──╭X───RX(0.117)──RZ(-0.677)──────────────────────────────╭X──RZ(-1.78)──╭X────────────────────────────────────────────────────┤ ⟨Z⟩ \n 1: ─────────────╰X──────────RX(-0.889)──RZ(-0.18)──╰C─────────────╰C──╭X──────────RZ(-1.61)───╭X──RX(-1.52)──RZ(1.76)─────╰C─────────────╰C──╭X──────────RZ(0.692)───╭X──RX(1.45)─────RZ(-2.31)──╰C─────────────╰C──╭X──RZ(-1.8)──╭X──────────────────────────────────┤ ⟨Z⟩ \n 4: ──RX(-1.56)───RZ(0.197)────────────────────────────────────────────╰C──────────────────────╰C──RX(0.792)──RZ(-0.0952)─────────────────────╰C──────────────────────╰C──RX(-0.0266)──RZ(2.14)──────────────────────╰C────────────╰C──RX(-1.47)──RY(1.26)──RZ(0.533)──┤     \n\n\n\n 0: ──H────────────╭C────────────RX(2.06)──RZ(-0.694)──╭X──RZ(-0.639)──╭X────────────RX(-4.13)──RZ(-0.657)───────────────────────────╭X──RZ(-0.457)──╭X───RX(-0.197)──RZ(0.521)───────────────────────────────╭X──RZ(-0.651)──╭X───RX(1.57)──RY(-0.448)───RZ(2.33)──────────────────────────────────╭C──RX(0.749)──RY(-0.542)──RZ(1.48)───┤ ⟨Z⟩ \n 1: ───────────────╰X────────────RX(1.02)──RZ(-0.178)──╰C──────────────╰C───────────╭X──────────RZ(-0.275)──╭X──RX(0.371)──RZ(1.2)───╰C──────────────╰C──╭X───────────RZ(-2.9)────╭X──RX(-0.176)──RZ(-0.92)───╰C──────────────╰C──╭X─────────RZ(0.179)───╭X─────────RX(1.34)──RY(0.343)──RZ(0.367)──╰X──RX(1.27)───RY(-0.546)──RZ(-1.72)──┤ ⟨Z⟩ \n 2: ──RX(-1.68)─────RZ(1.67)────╭X─────────RZ(1.13)────╭X───────────────────────────╰C──────────────────────╰C──RX(0.635)──RZ(0.84)──╭X──RZ(0.586)───╭X──╰C───────────────────────╰C──RX(-0.319)──RZ(-0.774)──╭X──RZ(0.144)───╭X──╰C─────────────────────╰C───────────────────────────────────────────────────────────────────────────────┤     \n 3: ──RX(-0.0904)───RZ(-0.625)──╰C─────────────────────╰C──RX(0.388)────RZ(-0.222)───────────────────────────────────────────────────╰C──────────────╰C───RX(1.19)────RZ(-0.114)──────────────────────────────╰C──────────────╰C──────────────────────────────────────────────────────────────────────────────────────────────────────────┤     \n\n"
     ]
    }
   ],
   "source": [
    "# To see the visual representation of what the discriminator and generator circuits look like\n",
    "\n",
    "@qml.qnode(dev, interface='tf')\n",
    "def generator_1(generator_weights):\n",
    "    generator(generator_weights)\n",
    "    return qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "@qml.qnode(dev, interface='tf')\n",
    "def discriminator_1(generator_weights):\n",
    "    discriminator(generator_weights)\n",
    "    return qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(0))\n",
    "\n",
    "discriminator_1(discriminator_weights)\n",
    "generator_1(generator_weights)\n",
    "print(discriminator_1.draw())\n",
    "print('\\n')\n",
    "print(generator_1.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}